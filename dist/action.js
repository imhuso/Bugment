#!/usr/bin/env node
"use strict";
var __createBinding = (this && this.__createBinding) || (Object.create ? (function(o, m, k, k2) {
    if (k2 === undefined) k2 = k;
    var desc = Object.getOwnPropertyDescriptor(m, k);
    if (!desc || ("get" in desc ? !m.__esModule : desc.writable || desc.configurable)) {
      desc = { enumerable: true, get: function() { return m[k]; } };
    }
    Object.defineProperty(o, k2, desc);
}) : (function(o, m, k, k2) {
    if (k2 === undefined) k2 = k;
    o[k2] = m[k];
}));
var __setModuleDefault = (this && this.__setModuleDefault) || (Object.create ? (function(o, v) {
    Object.defineProperty(o, "default", { enumerable: true, value: v });
}) : function(o, v) {
    o["default"] = v;
});
var __importStar = (this && this.__importStar) || (function () {
    var ownKeys = function(o) {
        ownKeys = Object.getOwnPropertyNames || function (o) {
            var ar = [];
            for (var k in o) if (Object.prototype.hasOwnProperty.call(o, k)) ar[ar.length] = k;
            return ar;
        };
        return ownKeys(o);
    };
    return function (mod) {
        if (mod && mod.__esModule) return mod;
        var result = {};
        if (mod != null) for (var k = ownKeys(mod), i = 0; i < k.length; i++) if (k[i] !== "default") __createBinding(result, mod, k[i]);
        __setModuleDefault(result, mod);
        return result;
    };
})();
Object.defineProperty(exports, "__esModule", { value: true });
exports.BugmentAction = void 0;
const core = __importStar(require("@actions/core"));
const github = __importStar(require("@actions/github"));
const fs = __importStar(require("fs"));
const path = __importStar(require("path"));
const child_process_1 = require("child_process");
const review_1 = require("./review");
const ignore_manager_1 = require("./ignore-manager");
const rule_manager_1 = require("./rule-manager");
class BugmentAction {
    constructor() {
        this.inputs = this.parseInputs();
        this.octokit = github.getOctokit(this.inputs.githubToken);
        this.prInfo = this.extractPRInfo();
    }
    parseInputs() {
        return {
            augmentAccessToken: core.getInput("augment_access_token", {
                required: true,
            }),
            augmentTenantUrl: core.getInput("augment_tenant_url", { required: true }),
            githubToken: core.getInput("github_token", { required: true }),
        };
    }
    extractPRInfo() {
        const context = github.context;
        if (!context.payload.pull_request) {
            throw new Error("This action can only be run on pull request events");
        }
        const pr = context.payload.pull_request;
        return {
            number: pr.number,
            title: pr.title || "",
            body: pr.body || "",
            baseSha: pr.base.sha,
            headSha: pr.head.sha,
            owner: context.repo.owner,
            repo: context.repo.repo,
        };
    }
    async run() {
        try {
            core.info("üöÄ Starting Bugment AI Code Review...");
            // Initialize ignore manager
            const workspaceDir = this.getWorkspaceDirectory();
            this.ignoreManager = new ignore_manager_1.IgnoreManager(workspaceDir);
            core.info(`üìã Initialized ignore manager with ${this.ignoreManager.getPatterns().length} patterns`);
            // Setup Augment authentication
            await this.setupAugmentAuth();
            // Generate diff file
            const diffPath = await this.generateDiffFile();
            // Perform code review
            const reviewResult = await this.performReview(diffPath);
            // Post review comment
            await this.postReviewComment(reviewResult);
            // Set outputs
            core.setOutput("review_result", reviewResult);
            core.setOutput("review_status", "success");
            core.info("‚úÖ Code review completed successfully");
        }
        catch (error) {
            const errorMessage = error instanceof Error ? error.message : String(error);
            core.setFailed(`‚ùå Code review failed: ${errorMessage}`);
            core.setOutput("review_status", "failed");
        }
    }
    async setupAugmentAuth() {
        core.info("üîê Setting up Augment authentication...");
        const configDir = path.join(process.env.HOME || "~", ".local/share/vim-augment");
        const configFile = path.join(configDir, "secrets.json");
        // Create config directory
        await fs.promises.mkdir(configDir, { recursive: true });
        // Create auth config
        const authConfig = {
            "augment.sessions": JSON.stringify({
                accessToken: this.inputs.augmentAccessToken,
                tenantURL: this.inputs.augmentTenantUrl,
                scopes: ["email"],
            }),
        };
        await fs.promises.writeFile(configFile, JSON.stringify(authConfig, null, 2));
        core.info("‚úÖ Augment authentication configured");
    }
    getWorkspaceDirectory() {
        // GitHub Actions sets GITHUB_WORKSPACE to the user's repository directory
        return process.env.GITHUB_WORKSPACE || process.cwd();
    }
    async getActualBaseSha(workspaceDir) {
        const githubSha = process.env.GITHUB_SHA;
        if (!githubSha) {
            core.info("üìù No GITHUB_SHA found, using original base SHA");
            return this.prInfo.baseSha;
        }
        // First check if this is a merge commit
        const isMergeCommit = await this.checkIfMergeCommit(workspaceDir, githubSha);
        if (!isMergeCommit) {
            core.info("üìù GITHUB_SHA is not a merge commit, using original base SHA");
            return this.prInfo.baseSha;
        }
        // Try to get the first parent of the merge commit
        return new Promise((resolve) => {
            const gitProcess = (0, child_process_1.spawn)("git", ["rev-parse", `${githubSha}^1`], {
                cwd: workspaceDir,
                stdio: ["pipe", "pipe", "pipe"],
            });
            let stdout = "";
            let stderr = "";
            gitProcess.stdout.on("data", (data) => {
                stdout += data.toString();
            });
            gitProcess.stderr.on("data", (data) => {
                stderr += data.toString();
            });
            gitProcess.on("close", (code) => {
                if (code === 0) {
                    const actualBaseSha = stdout.trim();
                    core.info(`üìù Successfully extracted actual base SHA: ${actualBaseSha}`);
                    resolve(actualBaseSha);
                }
                else {
                    core.info(`üìù Could not extract base SHA from merge commit, using original base SHA`);
                    core.debug(`Git error: ${stderr}`);
                    resolve(this.prInfo.baseSha);
                }
            });
            gitProcess.on("error", (error) => {
                core.info(`üìù Git command failed, using original base SHA`);
                core.debug(`Git error: ${error.message}`);
                resolve(this.prInfo.baseSha);
            });
        });
    }
    async checkIfMergeCommit(workspaceDir, sha) {
        return new Promise((resolve) => {
            const gitProcess = (0, child_process_1.spawn)("git", ["cat-file", "-p", sha], {
                cwd: workspaceDir,
                stdio: ["pipe", "pipe", "pipe"],
            });
            let stdout = "";
            gitProcess.stdout.on("data", (data) => {
                stdout += data.toString();
            });
            gitProcess.on("close", (code) => {
                if (code === 0) {
                    // Count parent lines - merge commits have multiple parent lines
                    const parentLines = stdout
                        .split("\n")
                        .filter((line) => line.startsWith("parent "));
                    const isMerge = parentLines.length > 1;
                    core.debug(`üìù Commit ${sha} has ${parentLines.length} parents, is merge: ${isMerge}`);
                    resolve(isMerge);
                }
                else {
                    core.debug(`üìù Could not check commit type for ${sha}`);
                    resolve(false);
                }
            });
            gitProcess.on("error", () => {
                resolve(false);
            });
        });
    }
    async generateDiffFile() {
        core.info("üìÑ Generating PR diff file...");
        const workspaceDir = this.getWorkspaceDirectory();
        const diffPath = path.join(workspaceDir, "pr_diff.patch");
        core.info(`üìÅ Using workspace directory: ${workspaceDir}`);
        // Get the correct base SHA for the PR diff
        const actualBaseSha = await this.getActualBaseSha(workspaceDir);
        core.info(`üîç Comparing ${actualBaseSha}...${this.prInfo.headSha}`);
        core.info(`üìù Original base SHA: ${this.prInfo.baseSha} (PR creation time)`);
        core.info(`üìù Actual base SHA: ${actualBaseSha} (merge commit base)`);
        let diffContent;
        try {
            // Method 1: Try to use git diff locally (most accurate)
            diffContent = await this.generateLocalDiffWithCorrectBase(workspaceDir, actualBaseSha);
            await fs.promises.writeFile(diffPath, diffContent);
            core.info(`‚úÖ Diff file generated using local git: ${diffPath}`);
        }
        catch (localError) {
            const errorMessage = localError instanceof Error ? localError.message : String(localError);
            core.warning(`Local git diff failed: ${errorMessage}`);
            // Method 2: Fallback to GitHub API with correct base
            try {
                diffContent = await this.generateApiDiffWithCorrectBase(actualBaseSha);
                await fs.promises.writeFile(diffPath, diffContent);
                core.info(`‚úÖ Diff file generated using GitHub API: ${diffPath}`);
            }
            catch (apiError) {
                const apiErrorMessage = apiError instanceof Error ? apiError.message : String(apiError);
                core.error(`GitHub API diff failed: ${apiErrorMessage}`);
                throw new Error(`Failed to generate diff: ${apiErrorMessage}`);
            }
        }
        // Parse the diff content for line validation
        this.parsedDiff = this.parseDiffContent(diffContent);
        core.info(`üìä Parsed diff for ${this.parsedDiff.files.size} files`);
        // Debug: Log first 1000 characters of diff content for troubleshooting
        core.info(`üìÑ Diff content preview: ${diffContent.substring(0, 1000)}...`);
        return diffPath;
    }
    async generateLocalDiffWithCorrectBase(workspaceDir, baseSha) {
        return new Promise((resolve, reject) => {
            const gitProcess = (0, child_process_1.spawn)("git", ["diff", `${baseSha}...${this.prInfo.headSha}`], {
                cwd: workspaceDir,
                stdio: ["pipe", "pipe", "pipe"],
            });
            let stdout = "";
            let stderr = "";
            gitProcess.stdout.on("data", (data) => {
                stdout += data.toString();
            });
            gitProcess.stderr.on("data", (data) => {
                stderr += data.toString();
            });
            gitProcess.on("close", (code) => {
                if (code === 0) {
                    resolve(stdout);
                }
                else {
                    reject(new Error(`Git diff failed with code ${code}: ${stderr}`));
                }
            });
            gitProcess.on("error", (error) => {
                reject(error);
            });
        });
    }
    async generateLocalDiff(workspaceDir) {
        return new Promise((resolve, reject) => {
            const gitProcess = (0, child_process_1.spawn)("git", ["diff", `${this.prInfo.baseSha}...${this.prInfo.headSha}`], {
                cwd: workspaceDir,
                stdio: ["pipe", "pipe", "pipe"],
            });
            let stdout = "";
            let stderr = "";
            gitProcess.stdout.on("data", (data) => {
                stdout += data.toString();
            });
            gitProcess.stderr.on("data", (data) => {
                stderr += data.toString();
            });
            gitProcess.on("close", (code) => {
                if (code === 0) {
                    resolve(stdout);
                }
                else {
                    reject(new Error(`Git diff failed with code ${code}: ${stderr}`));
                }
            });
            gitProcess.on("error", (error) => {
                reject(error);
            });
        });
    }
    async generateApiDiffWithCorrectBase(baseSha) {
        const diffResponse = await this.octokit.rest.repos.compareCommits({
            owner: this.prInfo.owner,
            repo: this.prInfo.repo,
            base: baseSha,
            head: this.prInfo.headSha,
            mediaType: {
                format: "diff",
            },
        });
        return diffResponse.data;
    }
    async generateApiDiff() {
        const diffResponse = await this.octokit.rest.repos.compareCommits({
            owner: this.prInfo.owner,
            repo: this.prInfo.repo,
            base: this.prInfo.baseSha,
            head: this.prInfo.headSha,
            mediaType: {
                format: "diff",
            },
        });
        return diffResponse.data;
    }
    parseDiffContent(diffContent) {
        const files = new Map();
        const lines = diffContent.split("\n");
        let currentFile = "";
        let currentHunk = null;
        let isIgnoringFile = false;
        let i = 0;
        core.info(`üìÑ Parsing diff content with ${lines.length} lines`);
        while (i < lines.length) {
            const line = lines[i];
            if (!line) {
                i++;
                continue;
            }
            // File header: diff --git a/file b/file
            if (line.startsWith("diff --git")) {
                const match = line.match(/diff --git a\/(.+) b\/(.+)/);
                if (match && match[2]) {
                    const filePath = match[2]; // Use the new file path
                    // Check if file should be ignored
                    if (this.ignoreManager && this.ignoreManager.shouldIgnore(filePath)) {
                        // Mark this file as ignored and skip all its content
                        isIgnoringFile = true;
                        currentFile = "";
                        currentHunk = null;
                        i++;
                        continue;
                    }
                    // File is not ignored
                    isIgnoringFile = false;
                    currentFile = filePath;
                    currentHunk = null;
                    core.info(`üìÅ Found file in diff: ${currentFile}`);
                    if (!files.has(currentFile)) {
                        files.set(currentFile, []);
                    }
                }
                else {
                    core.warning(`‚ö†Ô∏è Failed to parse git diff header: ${line}`);
                }
            }
            // Hunk header: @@ -oldStart,oldLines +newStart,newLines @@
            else if (line.startsWith("@@")) {
                // Skip hunk headers for ignored files
                if (isIgnoringFile) {
                    i++;
                    continue;
                }
                const match = line.match(/@@ -(\d+)(?:,(\d+))? \+(\d+)(?:,(\d+))? @@/);
                if (match && currentFile && match[1] && match[3]) {
                    const oldStart = parseInt(match[1], 10);
                    const oldLines = match[2] ? parseInt(match[2], 10) : 1;
                    const newStart = parseInt(match[3], 10);
                    const newLines = match[4] ? parseInt(match[4], 10) : 1;
                    currentHunk = {
                        filePath: currentFile,
                        oldStart,
                        oldLines,
                        newStart,
                        newLines,
                        lines: [],
                    };
                    core.info(`üìä Found hunk for ${currentFile}: lines ${newStart}-${newStart + newLines - 1}`);
                    files.get(currentFile).push(currentHunk);
                }
                else {
                    core.warning(`‚ö†Ô∏è Failed to parse hunk header: ${line}`);
                }
            }
            // Content lines
            else if (!isIgnoringFile && // Skip content lines for ignored files
                currentHunk &&
                currentFile &&
                (line.startsWith("+") || line.startsWith("-") || line.startsWith(" "))) {
                currentHunk.lines.push(line);
            }
            i++;
        }
        // Log summary of parsed diff
        const fileCount = files.size;
        const totalHunks = Array.from(files.values()).reduce((sum, hunks) => sum + hunks.length, 0);
        core.info(`üìä Diff parsing complete: ${fileCount} files, ${totalHunks} hunks (after applying ignore filters)`);
        // Log each file and its hunks for debugging
        for (const [filePath, hunks] of files.entries()) {
            core.info(`üìÅ File: ${filePath} has ${hunks.length} hunks`);
            hunks.forEach((hunk, index) => {
                core.info(`  üìä Hunk ${index + 1}: lines ${hunk.newStart}-${hunk.newStart + hunk.newLines - 1} (${hunk.lines.length} diff lines)`);
            });
        }
        return { files };
    }
    async performReview(diffPath) {
        core.info("ü§ñ Performing AI code review...");
        const workspaceDir = this.getWorkspaceDirectory();
        // Âä†ËΩΩÈ°πÁõÆËßÑÂàô
        const ruleManager = new rule_manager_1.RuleManager(workspaceDir);
        const projectRules = await ruleManager.loadAllRules();
        const reviewOptions = {
            projectPath: workspaceDir,
            prTitle: this.prInfo.title,
            prDescription: this.prInfo.body,
            diffPath: diffPath,
            repoOwner: this.prInfo.owner,
            repoName: this.prInfo.repo,
            commitSha: this.prInfo.headSha,
            projectRules: projectRules, // Ê∑ªÂä†È°πÁõÆËßÑÂàô
        };
        core.info(`üîç Analyzing project at: ${workspaceDir}`);
        if (projectRules) {
            core.info(`üìã Found project rules, prioritizing rule compliance checks`);
        }
        const result = await (0, review_1.performCodeReview)(reviewOptions);
        core.info("‚úÖ Code review completed");
        return result;
    }
    async postReviewComment(reviewResult) {
        core.info("üí¨ Posting review comment...");
        // Parse the review result to extract structured data
        const parsedResult = this.parseReviewResult(reviewResult);
        // Get previous review results for comparison and hide old reviews
        const previousReviews = await this.getPreviousReviewsAndHideOld();
        // Compare with previous reviews to identify fixed/new issues
        const comparison = this.compareReviews(parsedResult, previousReviews);
        // Create a unified review with both overview and line comments
        const commentBody = this.formatMainReviewComment(parsedResult, comparison);
        await this.createUnifiedPullRequestReview(commentBody, parsedResult);
        core.info("‚úÖ Review posted");
    }
    parseReviewResult(reviewResult) {
        core.info("üîç Starting to parse review result...");
        // Generate a unique review ID with PR association
        const prId = `pr${this.prInfo.number}`;
        const commitShort = this.prInfo.headSha.substring(0, 8);
        const timestampShort = Date.now().toString().slice(-6); // Last 6 digits for brevity
        const reviewId = `${prId}_${commitShort}_${timestampShort}`;
        const timestamp = new Date().toISOString();
        // Log the review result for debugging (first 500 chars)
        core.info(`üìù Review result preview: ${reviewResult.substring(0, 500)}...`);
        // Extract issues from the review result using regex patterns
        const issues = [];
        // Parse different types of issues from the review text
        // Updated patterns to match the prompt.md format exactly
        const bugPattern = /# Bugs\s*\n([\s\S]*?)(?=\n# |$)/g;
        const smellPattern = /# Code Smells\s*\n([\s\S]*?)(?=\n# |$)/g;
        const securityPattern = /# Security Issues\s*\n([\s\S]*?)(?=\n# |$)/g;
        const performancePattern = /# Performance Issues\s*\n([\s\S]*?)(?=\n# |$)/g;
        let issueId = 1;
        // Parse different issue types
        core.info("üîç Parsing bugs...");
        this.parseIssuesFromSection(reviewResult, bugPattern, "bug", issues, issueId);
        core.info("üîç Parsing code smells...");
        this.parseIssuesFromSection(reviewResult, smellPattern, "code_smell", issues, issueId);
        core.info("üîç Parsing security issues...");
        this.parseIssuesFromSection(reviewResult, securityPattern, "security", issues, issueId);
        core.info("üîç Parsing performance issues...");
        this.parseIssuesFromSection(reviewResult, performancePattern, "performance", issues, issueId);
        const result = {
            reviewId,
            timestamp,
            commitSha: this.prInfo.headSha,
            summary: this.extractSummaryFromReview(reviewResult),
            issues,
            totalIssues: issues.length,
        };
        core.info(`‚úÖ Parsing complete. Found ${result.totalIssues} total issues`);
        return result;
    }
    parseIssuesFromSection(reviewResult, pattern, type, issues, issueId) {
        const matches = reviewResult.match(pattern);
        if (matches && matches.length > 0) {
            // The pattern now captures the content after the header, so we use matches[1] if it exists
            const sectionContent = matches[0];
            core.info(`üîç Found ${type} section: ${sectionContent.substring(0, 100)}...`);
            // Extract individual issues from the section content
            const issueMatches = sectionContent.match(/## \d+\. .+?(?=## \d+\.|$)/gs);
            if (issueMatches && issueMatches.length > 0) {
                core.info(`üìù Found ${issueMatches.length} ${type} issues`);
                issueMatches.forEach((issueText, index) => {
                    const issue = this.parseIssueFromText(issueText, type, `${type}_${issueId + index}`);
                    if (issue) {
                        issues.push(issue);
                        core.info(`‚úÖ Parsed ${type} issue: ${issue.title}`);
                    }
                    else {
                        core.warning(`‚ö†Ô∏è Failed to parse ${type} issue from text: ${issueText.substring(0, 100)}...`);
                    }
                });
            }
            else {
                core.info(`‚ÑπÔ∏è No individual issues found in ${type} section`);
            }
        }
        else {
            core.info(`‚ÑπÔ∏è No ${type} section found in review result`);
        }
    }
    parseIssueFromText(text, type, id) {
        core.info(`üîç Parsing ${type} issue text: ${text.substring(0, 200)}...`);
        // Extract title from the issue heading
        const titleMatch = text.match(/## \d+\. (.+?)(?:\n|$)/);
        if (!titleMatch) {
            core.warning(`‚ö†Ô∏è No title found in ${type} issue text`);
            return null;
        }
        const title = titleMatch[1]?.trim() || "Unknown Issue";
        core.info(`üìù Found ${type} issue title: ${title}`);
        // Extract severity, description, location, etc. from the text
        const severityMatch = text.match(/\*\*‰∏•ÈáçÁ®ãÂ∫¶\*\*[Ôºö:]\s*üü°\s*\*\*(\w+)\*\*|\*\*‰∏•ÈáçÁ®ãÂ∫¶\*\*[Ôºö:]\s*üü¢\s*\*\*(\w+)\*\*|\*\*‰∏•ÈáçÁ®ãÂ∫¶\*\*[Ôºö:]\s*üî¥\s*\*\*(\w+)\*\*/);
        const locationMatch = text.match(/\*\*‰ΩçÁΩÆ\*\*[Ôºö:]\s*(.+?)(?:\n|$)/);
        const descriptionMatch = text.match(/\*\*ÊèèËø∞\*\*[Ôºö:]\s*([\s\S]*?)(?=\*\*‰ΩçÁΩÆ\*\*|\*\*Âª∫ËÆÆ‰øÆÊîπ\*\*|\*\*AI‰øÆÂ§çPrompt\*\*|$)/);
        const suggestionMatch = text.match(/\*\*Âª∫ËÆÆ‰øÆÊîπ\*\*[Ôºö:]\s*([\s\S]*?)(?=\*\*AI‰øÆÂ§çPrompt\*\*|$)/);
        const fixPromptMatch = text.match(/\*\*AI‰øÆÂ§çPrompt\*\*[Ôºö:]\s*```\s*([\s\S]*?)\s*```/);
        if (!descriptionMatch || !descriptionMatch[1]) {
            core.warning(`‚ö†Ô∏è No description found in ${type} issue: ${title}`);
            return null;
        }
        const severityText = severityMatch?.[1] ||
            severityMatch?.[2] ||
            severityMatch?.[3] ||
            "medium";
        const severity = this.mapSeverity(severityText);
        const description = descriptionMatch[1].trim();
        const location = locationMatch?.[1]?.trim() || "";
        // Parse file path and line number from location
        const { filePath, lineNumber, startLine, endLine } = this.parseLocationInfo(location);
        return {
            id,
            type,
            severity,
            title,
            description,
            location,
            filePath,
            lineNumber,
            startLine,
            endLine,
            fixPrompt: fixPromptMatch?.[1]?.trim(),
            suggestion: suggestionMatch?.[1]?.trim(),
        };
    }
    parseLocationInfo(location) {
        core.info(`üîç Parsing location info: "${location}"`);
        // Parse formats like:
        // "src/components/Button.tsx:45"
        // "src/utils/helper.js:12-18"
        // "README.md#L25-L30"
        // "[index.ts:16" (malformed format that we need to handle)
        // Handle malformed format with leading bracket
        let cleanLocation = location.trim();
        if (cleanLocation.startsWith("[")) {
            cleanLocation = cleanLocation.substring(1);
            core.info(`üîß Cleaned malformed location: "${cleanLocation}"`);
        }
        const fileLineMatch = cleanLocation.match(/^([^:]+):(\d+)(?:-(\d+))?/);
        const githubLineMatch = cleanLocation.match(/^([^#]+)#L(\d+)(?:-L(\d+))?/);
        if (fileLineMatch) {
            const [, filePath, startLineStr, endLineStr] = fileLineMatch;
            if (filePath && startLineStr) {
                const startLine = parseInt(startLineStr, 10);
                const endLine = endLineStr ? parseInt(endLineStr, 10) : undefined;
                const result = {
                    filePath: filePath.trim(),
                    lineNumber: endLine || startLine, // Use end line if available, otherwise start line
                    startLine,
                    endLine,
                };
                core.info(`‚úÖ Parsed file:line format: ${JSON.stringify(result)}`);
                return result;
            }
        }
        if (githubLineMatch) {
            const [, filePath, startLineStr, endLineStr] = githubLineMatch;
            if (filePath && startLineStr) {
                const startLine = parseInt(startLineStr, 10);
                const endLine = endLineStr ? parseInt(endLineStr, 10) : undefined;
                const result = {
                    filePath: filePath.trim(),
                    lineNumber: endLine || startLine,
                    startLine,
                    endLine,
                };
                core.info(`‚úÖ Parsed GitHub format: ${JSON.stringify(result)}`);
                return result;
            }
        }
        core.warning(`‚ö†Ô∏è Failed to parse location: "${location}"`);
        return {};
    }
    isLineInDiff(filePath, lineNumber) {
        core.info(`üîç Checking line ${filePath}:${lineNumber} - validation enabled for PR commit range`);
        if (!this.parsedDiff || !filePath || !lineNumber) {
            core.info(`‚ùå Missing diff data or invalid parameters`);
            return false;
        }
        // Debug: Log all available files in the parsed diff
        const availableFiles = Array.from(this.parsedDiff.files.keys());
        core.info(`üìÅ Available files in diff: ${availableFiles.join(", ")}`);
        // Try exact match first
        let hunks = this.parsedDiff.files.get(filePath);
        // If exact match fails, try to find a matching file with different path formats
        if (!hunks || hunks.length === 0) {
            core.info(`‚ùå No exact match for file: ${filePath}`);
            // Try to find files that end with the same path
            const normalizedPath = filePath.replace(/^\/+/, ""); // Remove leading slashes
            const matchingFile = availableFiles.find((file) => {
                const normalizedFile = file.replace(/^\/+/, "");
                return (normalizedFile === normalizedPath ||
                    file.endsWith("/" + normalizedPath) ||
                    normalizedFile.endsWith("/" + filePath) ||
                    file === normalizedPath);
            });
            if (matchingFile) {
                core.info(`‚úÖ Found matching file: ${matchingFile} for ${filePath}`);
                hunks = this.parsedDiff.files.get(matchingFile);
            }
            else {
                core.info(`‚ùå No matching file found for: ${filePath}`);
                core.info(`üìù Tried to match against: ${availableFiles.join(", ")}`);
                return false;
            }
        }
        if (!hunks || hunks.length === 0) {
            core.info(`‚ùå No hunks found for file: ${filePath}`);
            return false;
        }
        core.info(`üìä Found ${hunks.length} hunks for file: ${filePath}`);
        // Check if the line number falls within any hunk's new line range
        for (const hunk of hunks) {
            const hunkEndLine = hunk.newStart + hunk.newLines - 1;
            core.info(`üîç Checking hunk range: ${hunk.newStart}-${hunkEndLine} for line ${lineNumber}`);
            if (lineNumber >= hunk.newStart && lineNumber <= hunkEndLine) {
                // For PR review, we want to allow comments on any line within the diff range
                // This includes added lines (+), removed lines (-), and context lines ( )
                let currentNewLine = hunk.newStart;
                for (const hunkLine of hunk.lines) {
                    if (hunkLine.startsWith("+") || hunkLine.startsWith(" ")) {
                        if (currentNewLine === lineNumber) {
                            core.info(`‚úÖ Line ${lineNumber} found in diff range`);
                            return true; // Allow comments on any line in the PR diff
                        }
                        currentNewLine++;
                    }
                }
            }
        }
        core.info(`‚ùå Line ${lineNumber} not found in any diff hunk for ${filePath}`);
        return false;
    }
    mapSeverity(severityText) {
        const lowerText = severityText.toLowerCase();
        if (lowerText.includes("È´ò") || lowerText.includes("critical"))
            return "critical";
        if (lowerText.includes("‰∏≠") || lowerText.includes("medium"))
            return "medium";
        if (lowerText.includes("‰Ωé") || lowerText.includes("low"))
            return "low";
        return "medium";
    }
    extractTitleFromDescription(description) {
        // Extract the first sentence or first 50 characters as title
        const firstLine = description.split("\n")[0] || "";
        return firstLine.length > 50
            ? firstLine.substring(0, 47) + "..."
            : firstLine;
    }
    getFilesWithIssues(issues) {
        const fileMap = new Map();
        // Group issues by file
        issues.forEach((issue) => {
            if (issue.filePath) {
                if (!fileMap.has(issue.filePath)) {
                    fileMap.set(issue.filePath, []);
                }
                fileMap.get(issue.filePath).push(issue);
            }
        });
        // Convert to array with descriptions
        return Array.from(fileMap.entries())
            .map(([filePath, fileIssues]) => {
            const issueTypes = [
                ...new Set(fileIssues.map((issue) => this.getTypeName(issue.type))),
            ];
            const description = issueTypes.length > 1
                ? `${issueTypes.slice(0, -1).join(", ")}Âíå${issueTypes.slice(-1)[0]}ÈóÆÈ¢ò`
                : `${issueTypes[0]}ÈóÆÈ¢ò`;
            return {
                filePath,
                issues: fileIssues,
                description,
            };
        })
            .sort((a, b) => a.filePath.localeCompare(b.filePath));
    }
    getSeverityEmoji(severity) {
        switch (severity) {
            case "critical":
                return "üî¥";
            case "high":
                return "üü†";
            case "medium":
                return "üü°";
            case "low":
                return "üü¢";
            default:
                return "‚ö™";
        }
    }
    getTypeEmoji(type) {
        switch (type) {
            case "bug":
                return "üêõ";
            case "security":
                return "üîí";
            case "performance":
                return "‚ö°";
            case "code_smell":
                return "üîç";
            default:
                return "‚ùì";
        }
    }
    getTypeName(type) {
        switch (type) {
            case "bug":
                return "ÊΩúÂú® Bug";
            case "security":
                return "ÂÆâÂÖ®ÈóÆÈ¢ò";
            case "performance":
                return "ÊÄßËÉΩÈóÆÈ¢ò";
            case "code_smell":
                return "‰ª£Á†ÅÂºÇÂë≥";
            default:
                return "ÂÖ∂‰ªñÈóÆÈ¢ò";
        }
    }
    getSeverityDistribution(issues) {
        const counts = {
            critical: 0,
            high: 0,
            medium: 0,
            low: 0,
        };
        issues.forEach((issue) => {
            counts[issue.severity]++;
        });
        const parts = [];
        if (counts.critical > 0)
            parts.push(`üî¥${counts.critical}`);
        if (counts.high > 0)
            parts.push(`üü†${counts.high}`);
        if (counts.medium > 0)
            parts.push(`üü°${counts.medium}`);
        if (counts.low > 0)
            parts.push(`üü¢${counts.low}`);
        return parts.join(" ");
    }
    formatIssueForGitHub(issue, index) {
        let formatted = `#### ${index}. ${issue.title}\n\n`;
        // Use GitHub alert syntax for better visibility
        const alertType = issue.severity === "critical" || issue.severity === "high"
            ? "WARNING"
            : "NOTE";
        formatted += `> [!${alertType}]\n`;
        formatted += `> **‰∏•ÈáçÁ®ãÂ∫¶:** ${this.getSeverityEmoji(issue.severity)} ${this.getSeverityText(issue.severity)}\n\n`;
        formatted += `**üìù ÈóÆÈ¢òÊèèËø∞:**\n`;
        formatted += `${issue.description}\n\n`;
        if (issue.location) {
            formatted += `**üìç ÈóÆÈ¢ò‰ΩçÁΩÆ:**\n`;
            formatted += `\`${issue.location}\`\n\n`;
        }
        if (issue.fixPrompt) {
            formatted += `**üîß ‰øÆÂ§çÂª∫ËÆÆ:**\n`;
            formatted += `\`\`\`\n${issue.fixPrompt}\n\`\`\`\n\n`;
        }
        formatted += `---\n\n`;
        return formatted;
    }
    extractSummaryFromReview(reviewResult) {
        // Extract the summary section from the review
        const summaryMatch = reviewResult.match(/# Overall Comments[\s\S]*?(?=# |$)/);
        if (summaryMatch && summaryMatch[0]) {
            // Clean up the summary
            return summaryMatch[0].replace(/# Overall Comments\s*/, "").trim();
        }
        return "";
    }
    async getPreviousReviewsAndHideOld() {
        try {
            // Get all reviews on this PR
            const reviews = await this.octokit.rest.pulls.listReviews({
                owner: this.prInfo.owner,
                repo: this.prInfo.repo,
                pull_number: this.prInfo.number,
            });
            const reviewResults = [];
            // Parse previous AI Code Review reviews
            for (const review of reviews.data) {
                if (review.body?.includes("Bugment Code Review") &&
                    review.body?.includes("REVIEW_DATA:") &&
                    review.state !== "DISMISSED") {
                    try {
                        const reviewDataMatch = review.body.match(/REVIEW_DATA:\s*```json\s*([\s\S]*?)\s*```/);
                        if (reviewDataMatch && reviewDataMatch[1]) {
                            const reviewData = JSON.parse(reviewDataMatch[1]);
                            reviewResults.push(reviewData);
                        }
                    }
                    catch (error) {
                        core.warning(`Failed to parse previous review data: ${error}`);
                    }
                }
            }
            // Hide (minimize) previous Bugment reviews as outdated
            await this.hidePreviousBugmentComments();
            // Get previous line-level comments and mark resolved issues
            await this.markResolvedLineComments(reviewResults);
            // Sort by timestamp (newest first)
            return reviewResults.sort((a, b) => new Date(b.timestamp).getTime() - new Date(a.timestamp).getTime());
        }
        catch (error) {
            core.warning(`Failed to get previous reviews: ${error}`);
            return [];
        }
    }
    async hidePreviousBugmentComments() {
        try {
            core.info("üîç Looking for previous Bugment reviews to hide...");
            // Get current time to avoid hiding very recent reviews (within last 30 seconds)
            const cutoffTime = new Date(Date.now() - 30000); // 30 seconds ago
            // Get all reviews on this PR
            const reviews = await this.octokit.rest.pulls.listReviews({
                owner: this.prInfo.owner,
                repo: this.prInfo.repo,
                pull_number: this.prInfo.number,
            });
            const reviewsToHide = [];
            // Check reviews for Bugment signature
            for (const review of reviews.data) {
                const reviewDate = new Date(review.submitted_at || new Date().toISOString());
                if (this.isBugmentReview(review.body || "") &&
                    reviewDate < cutoffTime &&
                    review.state !== "DISMISSED") {
                    reviewsToHide.push({
                        id: review.id.toString(),
                        nodeId: review.node_id,
                        url: review.html_url,
                        createdAt: review.submitted_at || new Date().toISOString(),
                        state: review.state,
                    });
                }
            }
            if (reviewsToHide.length > 0) {
                core.info(`üìù Found ${reviewsToHide.length} previous Bugment reviews to hide`);
                let hiddenCount = 0;
                for (const review of reviewsToHide) {
                    try {
                        await this.minimizeComment(review.nodeId);
                        hiddenCount++;
                        core.info(`‚úÖ Hidden review (${review.state}) from ${review.createdAt}: ${review.url}`);
                    }
                    catch (error) {
                        core.warning(`‚ö†Ô∏è Failed to hide review ${review.id}: ${error}`);
                    }
                }
                core.info(`üéØ Successfully hidden ${hiddenCount}/${reviewsToHide.length} previous Bugment reviews`);
            }
            else {
                core.info("‚ÑπÔ∏è No previous Bugment reviews found to hide");
            }
        }
        catch (error) {
            core.warning(`Failed to hide previous Bugment reviews: ${error}`);
        }
    }
    isBugmentReview(body) {
        // Check specifically for the Bugment review signature
        const bugmentReviewSignature = "ü§ñ Powered by [Bugment AI Code Review](https://github.com/J3n5en/Bugment)";
        // Also check for other Bugment review signatures as fallback
        const bugmentSignatures = [
            bugmentReviewSignature,
            "Bugment Code Review",
            "Bugment AI Code Review",
            "ü§ñ Powered by Bugment",
            "REVIEW_DATA:",
        ];
        return bugmentSignatures.some((signature) => body.includes(signature));
    }
    async minimizeComment(commentNodeId) {
        const mutation = `
      mutation minimizeComment($id: ID!) {
        minimizeComment(input: { classifier: OUTDATED, subjectId: $id }) {
          clientMutationId
        }
      }
    `;
        await this.octokit.graphql(mutation, {
            id: commentNodeId,
        });
    }
    async markResolvedLineComments(previousReviews) {
        try {
            // Use GraphQL to get review threads and resolve them
            const reviewThreads = await this.getReviewThreadsWithComments();
            let resolvedCount = 0;
            let processedCount = 0;
            // Find previous AI-generated comments that are no longer relevant
            for (const thread of reviewThreads) {
                if (thread.isResolved) {
                    continue; // Skip already resolved threads
                }
                // Check if this thread contains AI-generated comments
                const hasAIComment = thread.comments.some((comment) => comment.body?.includes("**üêõ") ||
                    comment.body?.includes("**üîç") ||
                    comment.body?.includes("**üîí") ||
                    comment.body?.includes("**‚ö°"));
                if (hasAIComment) {
                    processedCount++;
                    // Check if the issue is still relevant based on the first comment in the thread
                    const firstComment = thread.comments[0];
                    const isStillRelevant = this.isCommentStillRelevant(firstComment, previousReviews);
                    if (!isStillRelevant) {
                        // Use GraphQL to resolve the conversation
                        try {
                            await this.resolveReviewThread(thread.id);
                            resolvedCount++;
                            core.info(`‚úÖ Resolved conversation thread ${thread.id}`);
                        }
                        catch (error) {
                            core.warning(`Failed to resolve thread ${thread.id}: ${error}`);
                        }
                    }
                }
            }
            if (processedCount > 0) {
                core.info(`üìù Processed ${processedCount} review threads, resolved ${resolvedCount} conversations`);
            }
        }
        catch (error) {
            core.warning(`Failed to process review threads: ${error}`);
        }
    }
    async getReviewThreadsWithComments() {
        const query = `
      query($owner: String!, $name: String!, $number: Int!) {
        repository(owner: $owner, name: $name) {
          pullRequest(number: $number) {
            reviewThreads(first: 100) {
              nodes {
                id
                isResolved
                comments(first: 50) {
                  nodes {
                    id
                    body
                    path
                    line
                    author {
                      login
                    }
                  }
                }
              }
            }
          }
        }
      }
    `;
        try {
            const response = await this.octokit.graphql(query, {
                owner: this.prInfo.owner,
                name: this.prInfo.repo,
                number: this.prInfo.number,
            });
            return response.repository.pullRequest.reviewThreads.nodes || [];
        }
        catch (error) {
            core.warning(`Failed to fetch review threads: ${error}`);
            return [];
        }
    }
    async resolveReviewThread(threadId) {
        const mutation = `
      mutation($threadId: ID!) {
        resolveReviewThread(input: { threadId: $threadId }) {
          thread {
            id
            isResolved
          }
        }
      }
    `;
        await this.octokit.graphql(mutation, {
            threadId: threadId,
        });
    }
    isCommentStillRelevant(comment, previousReviews) {
        // Skip if already marked as resolved (for backward compatibility)
        if (comment.body?.includes("‚úÖ **Â∑≤Ëß£ÂÜ≥**") ||
            comment.body?.includes("~~")) {
            return true; // Don't process already resolved comments
        }
        const filePath = comment.path;
        const lineNumber = comment.line;
        // Check if the current review (latest) still has issues at this location
        if (previousReviews.length > 0) {
            const latestReview = previousReviews[0]; // Reviews are sorted by timestamp (newest first)
            if (latestReview && latestReview.issues) {
                const hasCurrentIssueAtLocation = latestReview.issues.some((issue) => issue.filePath === filePath && issue.lineNumber === lineNumber);
                // If the latest review still has an issue at this location, the comment is still relevant
                return hasCurrentIssueAtLocation;
            }
        }
        return true; // Assume still relevant if we can't determine otherwise
    }
    compareReviews(currentReview, previousReviews) {
        if (previousReviews.length === 0) {
            // First review - all issues are new
            return {
                newIssues: currentReview.issues,
                fixedIssues: [],
                persistentIssues: [],
                modifiedIssues: [],
                fixedCount: 0,
                newCount: currentReview.issues.length,
                persistentCount: 0,
            };
        }
        const latestPreviousReview = previousReviews[0];
        if (!latestPreviousReview) {
            // No previous review found, treat all as new
            return {
                newIssues: currentReview.issues,
                fixedIssues: [],
                persistentIssues: [],
                modifiedIssues: [],
                fixedCount: 0,
                newCount: currentReview.issues.length,
                persistentCount: 0,
            };
        }
        const newIssues = [];
        const fixedIssues = [];
        const persistentIssues = [];
        const modifiedIssues = [];
        // Create maps for easier lookup
        const currentIssueMap = new Map(currentReview.issues.map((issue) => [
            this.getIssueSignature(issue),
            issue,
        ]));
        const previousIssueMap = new Map(latestPreviousReview.issues.map((issue) => [
            this.getIssueSignature(issue),
            issue,
        ]));
        // Find new and persistent issues
        for (const currentIssue of currentReview.issues) {
            const signature = this.getIssueSignature(currentIssue);
            const previousIssue = previousIssueMap.get(signature);
            if (!previousIssue) {
                newIssues.push(currentIssue);
            }
            else if (this.issuesAreSimilar(currentIssue, previousIssue)) {
                if (currentIssue.description !== previousIssue.description) {
                    modifiedIssues.push({
                        previous: previousIssue,
                        current: currentIssue,
                    });
                }
                else {
                    persistentIssues.push(currentIssue);
                }
            }
        }
        // Find fixed issues
        for (const previousIssue of latestPreviousReview.issues) {
            const signature = this.getIssueSignature(previousIssue);
            if (!currentIssueMap.has(signature)) {
                fixedIssues.push(previousIssue);
            }
        }
        return {
            newIssues,
            fixedIssues,
            persistentIssues,
            modifiedIssues,
            fixedCount: fixedIssues.length,
            newCount: newIssues.length,
            persistentCount: persistentIssues.length,
        };
    }
    getIssueSignature(issue) {
        // Create a signature based on type, location, and key parts of description
        const locationPart = issue.location || issue.filePath || "";
        const descriptionPart = issue.description.substring(0, 100);
        return `${issue.type}_${locationPart}_${descriptionPart}`.replace(/\s+/g, "_");
    }
    issuesAreSimilar(issue1, issue2) {
        return (issue1.type === issue2.type &&
            issue1.location === issue2.location &&
            issue1.filePath === issue2.filePath &&
            issue1.lineNumber === issue2.lineNumber);
    }
    formatMainReviewComment(reviewResult, comparison) {
        let content = `## Bugment Code Review\n\n`;
        // Add PR summary based on the original review
        if (reviewResult.summary && reviewResult.summary.trim()) {
            content += `${reviewResult.summary}\n\n`;
        }
        // Add reviewed changes section
        content += `### ÂÆ°Êü•ÁªìÊûú\n\n`;
        content += `Bugment ÂÆ°Êü•‰∫Ü‰ª£Á†ÅÂèòÊõ¥Âπ∂ÁîüÊàê‰∫Ü ${reviewResult.totalIssues} Êù°ËØÑËÆ∫„ÄÇ\n\n`;
        // Check if this is a clean PR (no issues found)
        const hasAnyIssues = reviewResult.totalIssues > 0;
        // Create file summary table if there are issues with file locations
        const filesWithIssues = this.getFilesWithIssues(reviewResult.issues);
        if (filesWithIssues.length > 0) {
            content += `| Êñá‰ª∂ | ÂèëÁé∞ÁöÑÈóÆÈ¢ò |\n`;
            content += `| ---- | ---------- |\n`;
            filesWithIssues.forEach(({ filePath, issues, description }) => {
                const issueCount = issues.length;
                const severityDistribution = this.getSeverityDistribution(issues);
                content += `| ${filePath} | ${issueCount} ‰∏™ÈóÆÈ¢ò (${severityDistribution}) - ${description} |\n`;
            });
            content += `\n`;
        }
        // Add status information if there are changes
        const hasStatusChanges = comparison.fixedCount > 0 ||
            comparison.newCount > 0 ||
            comparison.persistentCount > 0;
        if (hasStatusChanges) {
            content += `### ÂèòÊõ¥ÊëòË¶Å\n\n`;
            if (comparison.fixedCount > 0) {
                content += `- ‚úÖ **${comparison.fixedCount}** ‰∏™ÈóÆÈ¢òÂ∑≤‰øÆÂ§ç\n`;
            }
            if (comparison.newCount > 0) {
                content += `- üÜï **${comparison.newCount}** ‰∏™Êñ∞ÈóÆÈ¢òÂèëÁé∞\n`;
            }
            if (comparison.persistentCount > 0) {
                content += `- ‚ö†Ô∏è **${comparison.persistentCount}** ‰∏™ÈóÆÈ¢ò‰ªçÈúÄÂÖ≥Ê≥®\n`;
            }
            content += `\n`;
        }
        // Show success message for clean PRs
        if (!hasAnyIssues && !hasStatusChanges) {
            content += `### üéâ ‰ºòÁßÄÁöÑÂ∑•‰ΩúÔºÅ\n\n`;
            content += `Ê≠§ Pull Request Êú™ÂèëÁé∞‰ªª‰ΩïÈóÆÈ¢òÔºå‰ª£Á†ÅÁ¨¶ÂêàË¥®ÈáèÊ†áÂáÜ„ÄÇ\n\n`;
        }
        // Add issues summary for low confidence issues (if any)
        const lowConfidenceIssues = reviewResult.issues.filter((issue) => issue.severity === "low");
        if (lowConfidenceIssues.length > 0) {
            content += `<details>\n`;
            content += `<summary>Áî±‰∫éÁΩÆ‰ø°Â∫¶ËæÉ‰ΩéËÄåÊäëÂà∂ÁöÑËØÑËÆ∫ (${lowConfidenceIssues.length})</summary>\n\n`;
            content += `Ëøô‰∫õÈóÆÈ¢òÂ∑≤Ë¢´ËØÜÂà´Ôºå‰ΩÜÂèØËÉΩÊòØËØØÊä•ÊàñËΩªÂæÆÂª∫ËÆÆ„ÄÇ\n\n`;
            content += `</details>\n\n`;
        }
        // Add footer with action source
        content += `\n---\n*ü§ñ Powered by [Bugment AI Code Review](https://github.com/J3n5en/Bugment)*\n\n`;
        // Add hidden review data for future parsing
        const reviewDataJson = JSON.stringify(reviewResult, null, 2);
        const hiddenData = `<!-- REVIEW_DATA:\n\`\`\`json\n${reviewDataJson}\n\`\`\`\n-->`;
        return content + hiddenData;
    }
    formatOriginalReviewContent(reviewResult) {
        let content = "";
        // Add summary if exists
        if (reviewResult.summary && reviewResult.summary.trim()) {
            content += reviewResult.summary + "\n\n";
        }
        if (reviewResult.issues.length > 0) {
            // Group issues by type
            const issuesByType = {
                bug: reviewResult.issues.filter((i) => i.type === "bug"),
                security: reviewResult.issues.filter((i) => i.type === "security"),
                performance: reviewResult.issues.filter((i) => i.type === "performance"),
                code_smell: reviewResult.issues.filter((i) => i.type === "code_smell"),
            };
            // Create a summary table first
            content += `### üìã ÈóÆÈ¢òÁªüËÆ°\n\n`;
            content += `| Á±ªÂûã | Êï∞Èáè | ‰∏•ÈáçÁ®ãÂ∫¶ÂàÜÂ∏É |\n`;
            content += `|------|------|-------------|\n`;
            Object.entries(issuesByType).forEach(([type, issues]) => {
                if (issues.length > 0) {
                    const typeEmoji = this.getTypeEmoji(type);
                    const typeName = this.getTypeName(type);
                    const severityCount = this.getSeverityDistribution(issues);
                    content += `| ${typeEmoji} ${typeName} | ${issues.length} | ${severityCount} |\n`;
                }
            });
            content += `\n`;
            // Show issues by type in collapsible sections
            if (issuesByType.bug.length > 0) {
                content += `<details>\n`;
                content += `<summary>üêõ ÊΩúÂú® Bug (${issuesByType.bug.length} ‰∏™) - ÁÇπÂáªÂ±ïÂºÄËØ¶ÊÉÖ</summary>\n\n`;
                issuesByType.bug.forEach((issue, index) => {
                    content += this.formatIssueForGitHub(issue, index + 1);
                });
                content += `</details>\n\n`;
            }
            if (issuesByType.security.length > 0) {
                content += `<details>\n`;
                content += `<summary>üîí ÂÆâÂÖ®ÈóÆÈ¢ò (${issuesByType.security.length} ‰∏™) - ÁÇπÂáªÂ±ïÂºÄËØ¶ÊÉÖ</summary>\n\n`;
                issuesByType.security.forEach((issue, index) => {
                    content += this.formatIssueForGitHub(issue, index + 1);
                });
                content += `</details>\n\n`;
            }
            if (issuesByType.performance.length > 0) {
                content += `<details>\n`;
                content += `<summary>‚ö° ÊÄßËÉΩÈóÆÈ¢ò (${issuesByType.performance.length} ‰∏™) - ÁÇπÂáªÂ±ïÂºÄËØ¶ÊÉÖ</summary>\n\n`;
                issuesByType.performance.forEach((issue, index) => {
                    content += this.formatIssueForGitHub(issue, index + 1);
                });
                content += `</details>\n\n`;
            }
            if (issuesByType.code_smell.length > 0) {
                content += `<details>\n`;
                content += `<summary>üîç ‰ª£Á†ÅÂºÇÂë≥ (${issuesByType.code_smell.length} ‰∏™) - ÁÇπÂáªÂ±ïÂºÄËØ¶ÊÉÖ</summary>\n\n`;
                issuesByType.code_smell.forEach((issue, index) => {
                    content += this.formatIssueForGitHub(issue, index + 1);
                });
                content += `</details>\n\n`;
            }
        }
        return content;
    }
    formatLineComment(issue) {
        const severityText = this.getSeverityText(issue.severity);
        let comment = `**${this.getTypeEmoji(issue.type)} ${this.getTypeName(issue.type)}** - ${this.getSeverityEmoji(issue.severity)} ${severityText}\n\n`;
        comment += `${issue.description}\n\n`;
        if (issue.suggestion) {
            comment += "```suggestion\n";
            comment += issue.suggestion;
            comment += "\n```\n\n";
        }
        if (issue.fixPrompt) {
            comment += `**üîß ‰øÆÂ§çÂª∫ËÆÆ:**\n\`\`\`\n${issue.fixPrompt}\n\`\`\``;
        }
        return comment;
    }
    getSeverityText(severity) {
        switch (severity) {
            case "critical":
                return "‰∏•Èáç";
            case "high":
                return "È´ò";
            case "medium":
                return "‰∏≠Á≠â";
            case "low":
                return "ËΩªÂæÆ";
            default:
                return "‰∏≠Á≠â";
        }
    }
    determineReviewEvent(reviewResult) {
        if (reviewResult.totalIssues > 0) {
            const hasCriticalOrHighIssues = reviewResult.issues.some((issue) => issue.severity === "critical" || issue.severity === "high");
            if (hasCriticalOrHighIssues) {
                return "REQUEST_CHANGES";
            }
        }
        return "COMMENT";
    }
    async createUnifiedPullRequestReview(commentBody, reviewResult) {
        // Create line-level comments for issues with file locations
        const lineComments = [];
        let validLineComments = 0;
        let invalidLineComments = 0;
        // Create line-level comments for each issue
        for (const issue of reviewResult.issues) {
            if (issue.filePath && issue.lineNumber) {
                // Validate that the line is within the diff
                if (!this.isLineInDiff(issue.filePath, issue.lineNumber)) {
                    core.warning(`‚ö†Ô∏è Skipping line comment for ${issue.filePath}:${issue.lineNumber} - not in diff range`);
                    invalidLineComments++;
                    continue;
                }
                const lineCommentBody = this.formatLineComment(issue);
                const lineComment = {
                    path: issue.filePath,
                    line: issue.lineNumber,
                    body: lineCommentBody,
                    side: "RIGHT",
                };
                // Disable multi-line comments to avoid GitHub API errors
                // Multi-line comments require start_line and line to be in the same hunk
                // which is complex to validate, so we use single-line comments only
                if (issue.startLine &&
                    issue.endLine &&
                    issue.startLine !== issue.endLine) {
                    core.info(`üìù Converting multi-line comment (${issue.startLine}-${issue.endLine}) to single-line comment at line ${issue.lineNumber}`);
                }
                lineComments.push(lineComment);
                validLineComments++;
            }
        }
        core.info(`üìä Line comments: ${validLineComments} valid, ${invalidLineComments} skipped (not in diff)`);
        // Determine the review event based on issues found
        const event = this.determineReviewEvent(reviewResult);
        // Create a single unified review with both overview and line comments
        const reviewParams = {
            owner: this.prInfo.owner,
            repo: this.prInfo.repo,
            pull_number: this.prInfo.number,
            body: commentBody,
            event: event,
            commit_id: this.prInfo.headSha,
        };
        // Add line comments if any exist
        if (lineComments.length > 0) {
            reviewParams.comments = lineComments;
            core.info(`üìù Creating unified review with ${lineComments.length} line comments`);
        }
        else {
            core.info(`üìù Creating review with overview only (no line comments)`);
        }
        await this.octokit.rest.pulls.createReview(reviewParams);
    }
}
exports.BugmentAction = BugmentAction;
// Main execution
async function main() {
    const action = new BugmentAction();
    await action.run();
}
if (require.main === module) {
    main().catch((error) => {
        core.setFailed(error.message);
        process.exit(1);
    });
}
//# sourceMappingURL=action.js.map